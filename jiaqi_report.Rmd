---
title: "Jiaqi report"
author: "Li Sun"
date: "October 12, 2015"
output: pdf_document
---

# Load packages
load necessary packages
```{r, echo=FALSE, results='hide', message=FALSE}
suppressWarnings(library(dplyr))
suppressWarnings(library(ggplot2))
suppressWarnings(library(gplots))
suppressWarnings(library(RColorBrewer))
suppressWarnings(library(lsr))
suppressWarnings(library(xtable))
# suppressWarnings(library(lme4))
suppressWarnings(library(car))
suppressWarnings(library(knitr))
```


# Load data
Data comes from Dr. Jiaqi Li in csv file.
```{r, echo=FALSE, message=FALSE}
# setwd("C:/Users/user/Dropbox/jiaqi")
# setwd("/home/li/Dropbox/jiaqi")
raw <- read.csv("Dissertation_Survey.csv", stringsAsFactors=FALSE)
#Select only needed variables
df <- raw[, c(12,13,14,15,16,17, 43:46,47, 65:74)]
names(df) <- c("gender", "age", "degree", "stay","marital","religion", "sla1", "sla2", "sla3", "sla4", "sla_id", "y1", "y2", "y3", "y4", "y5", "y6", "y7", "y8", "y9", "y10")
```

# Data cleaning
1. variables needed to be edited: 'age', 'stay'
There is one value which is "adult", we change that one to 18, according to the info that he has 89 TOFLE score and stayed in US for 18 month. We change this to 25, which is average age of F1 student who came here after undergraduate (23.5) and master study(26.5). There is also another invalid entry which is 3. We believe it is imput error. and change it to 30
For stay, there is an entry which is "whole life", we change that to 12 * age.

```{r, echo=FALSE, results='hide', message=FALSE}
################### age
df$age
df$age[df$age=="adult"] <- "25"
df$age[df$age==" "] <- NA
df$age <- as.numeric(df$age)
df$age[df$age==3] <- 30

################### stay
df$stay
wlidx <- df$stay=="Whole Life"
df$stay[df$stay == " "] <- NA
df$stay<- gsub("months?", "", df$stay)
df$stay[(!grepl("[0-9]", df$stay))&!is.na(df$stay)] <- "0"
for(i in seq(df$stay)){
  if(grepl(" *([0-9]+) ?ye?a?rs?.*", df$stay[i])){
    df$stay[i] <-gsub(" *([0-9]+) ?ye?a?rs?.*", "\\1", df$stay[i])
    df$stay[i] <-as.character(as.numeric(df$stay[i])*12)
  }
}
df$stay <- as.numeric(gsub(" ", "", df$stay))
# The value "whole life" is change to the person's age times 12
df$stay[wlidx] <- df$age[wlidx] * 12
```

2. Construct new variable "SL-ASIA values score" ("SLval"), based on the SUINN-LEW ASIA SCALE (question 22~23)
coding:
1. Do not believe ...... 5. strongly believe
```{r, echo=FALSE, message=FALSE}
df$SLval <- rep(0, nrow(df))
for(i in 1:nrow(df)){
  if(is.na(df[i,7])|is.na(df[i,8])){df$SLval[i] <- NA;next}
  if(df[i,7] <= 2){
    if(df[i,8] <= 2){df$SLval[i] <- "N"}
    else if(df[i, 8] ==3){df$SLval[i] <- "(W)"}
    else if(df[i, 8] > 3){df$SLval[i] <- "W"}
  }
  else if(df[i,7] == 3){
    if(df[i,8] <= 2){df$SLval[i] <- "(A)"}
    else if(df[i, 8] ==3){df$SLval[i] <- "(B)"}
    else if(df[i, 8] > 3){df$SLval[i] <- "W"}
  }
  else{
    if(df[i,8] <= 3){df$SLval[i] <- "A"}
    else{df$SLval[i] <- "B"}
  }
}
### If you only want 4 groups with no "()"
df$SLval4 <- gsub("[()]", "", df$SLval)
table(df$SLval4)
```

3. Construct new variable "SL-ASIA behavioral competencies score" ("SLcom"), based on the SUINN-LEW ASIA SCALE (question 24~25)
1. do not fit ......  5. fit very well
```{r, echo=FALSE, message=FALSE}
df$SLcom <- rep(0, nrow(df))
for(i in 1:nrow(df)){
  if(is.na(df[i,9])|is.na(df[i,10])){df$SLcom[i] <- NA;next}
  if(df[i,9] <= 2){
    if(df[i,10] <= 2){df$SLcom[i] <- "N"}
    else if(df[i, 10] ==3){df$SLcom[i] <- "(W)"}
    else if(df[i, 10] > 3){df$SLcom[i] <- "W"}
  }
  else if(df[i,9] == 3){
    if(df[i,10] <= 2){df$SLcom[i] <- "(A)"}
    else if(df[i, 10] ==3){df$SLcom[i] <- "(B)"}
    else if(df[i, 10] > 3){df$SLcom[i] <- "W"}
  }
  else{
    if(df[i,10] <= 3){df$SLcom[i] <- "A"}
    else{df$SLcom[i] <- "B"}
  }
}
### If you only want 4 groups with no "()"
df$SLcom4 <- gsub("[()]", "", df$SLcom)
table(df$SLcom4)
table(df[,c(23,25)])
```

4. Construct new variable "SL-ASIA self-identity score" ("sla_id"), based on the SUINN-LEW ASIA SCALE (question 26)
coding
1. I consider myself basically an Asian person (e.g., Chinese, Japanese, Korean, Vietnamese, etc.). Even though I live and work in America, I still view myself basically as an Asian person.
5. I consider myself basically as an American. Even though I have an Asian background and characteristics, I still view myself basically as an American.
7. I consider myself as an Asian-American, although deep down I always know I am an Asian.
9. I consider myself as an Asian-American, although deep down, I view myself as an American first.
10. I consider myself as an Asian-American. I have both Asian and American characteristics, and I view myself as a blend of both.

We found `r sum(df$sla_id==1, na.rm=T)/sum(!is.na(df$sla_id))` responders chose 1 and there is one value "2" which is not included in coding rubric and we will change it to 9 because 9 is missing here. And as suggested we will treat this variable as numeric. From 1 to 5, 1 is very asian and 5 is very american identification.

```{r, echo=FALSE, message=FALSE}
df$sla_id[df$sla_id==2&!is.na(df$sla_id)] <- 9
# re-order the factors
df$sla_id <- factor(as.factor(df$sla_id), levels=c("1", "7", "10", "9", "5"))
df$sla_id <- as.numeric(df$sla_id)
```

5. Construct new val indicating individual attitude to counseling.
for all original question
values:
1. strongly disgree
2. disgree
3. agree
4. strongly agree
Calculating based on
Whittlesey, V. (2001). Diversity activities for psychology. Boston: Allyn and
Bacon, and Fischer, E., and Farina, A. (1995). Attitudes toward seeking psychological
professional help: A shortened form and considerations for research. Journal of College Student
Development, 36, 368-373.

```{r, echo=FALSE, message=FALSE}
#Reverse several questions' scores
df$y2 <- 5-df$y2
df$y4 <- 5-df$y4
df$y8 <- 5-df$y8
df$y9 <- 5-df$y9
df$y10 <- 5-df$y10
df$y <- rowSums(df[,12:21])
hist(df$y, breaks=15, col="light blue", xlab ="scores of attitude seeking professional help")
summary(df$y)
```

# Exploratory data analysis
## Visualize the relationship among the 3 scores from "Suinn-Lew Asian Self Identity Acculturation"
1. Visualize the relationship between different grouping methods of individuals acculturation
```{r, echo=FALSE, message=FALSE}
### Based on 7 groups
x <- data.frame(val=factor(df$SLval, levels=c("A", "(A)", "N", "B", "(B)", "(W)", "W")), com=factor(df$SLcom, levels=c("A", "(A)", "N", "B", "(B)", "(W)", "W")), id = df$sla_id)
x2<-x[complete.cases(x),]
# ggplot(data = x2, aes(x = val, y = com, colour=id)) + stat_sum(aes(size = factor(..n..)), geom = "point") + scale_size_discrete(range = c(3, 20)) + labs(title="3 ACCULTURATION SCORES based on 7 groupss", x="SL-ASIA values score", y="SL-ASIA behavioral competencies score", colour = "SL-ASIA self-identity score", size="number of individual")                                                 
### Based on 4 groups
x <- data.frame(val=factor(df$SLval4, levels=c("A", "N", "B", "W")), com=factor(df$SLcom4, levels=c("A", "N", "B", "W")), id = df$sla_id)
x2<-x[complete.cases(x),]
ggplot(data = x2, aes(x = val, y = com, colour=id)) + stat_sum(aes(size = factor(..n..)), geom = "point") + scale_size_discrete(range = c(3, 20))+ labs(title="3 ACCULTURATION SCORES based on 7 groupss", x="SL-ASIA values score", y="SL-ASIA behavioral competencies score", colour = "SL-ASIA self-identity score", size="number of individual") + guides(size=FALSE)

### Path figuer
```

We found that the most asian students identify themselves as asian no matter how good they fit in western life.

2. Visualize the relationship between the 3 scores and attitudes for seeking professional counseling.
This need 

```{r echo=FALSE, message=FALSE, fig.width=6, fig.height=4}
x <- data.frame(val=factor(df$SLval4, levels=c("A", "N", "B", "W")), com=factor(df$SLcom4, levels=c("A", "N", "B", "W")), id = df$sla_id, y=df$y)
x2<-x[complete.cases(x),]
# The relationship between our acculturation scores and our response
ggplot(aes(x=val, y=y, fill=val), data=x2) + geom_boxplot(outlier.colour = "red", outlier.size = 5);
```

```{r echo=FALSE, message=FALSE, fig.width=6, fig.height=4}
ggplot(aes(x=com, y=y, fill=com), data=x2) + geom_boxplot(outlier.colour = "red", outlier.size = 5);
```

```{r echo=FALSE, message=FALSE, fig.width=6, fig.height=4}
ggplot(aes(x=as.numeric(id), y=y, colour=id), data=x2) + stat_sum(aes(size = factor(..n..)), geom="point", alpha=0.8) + scale_size_discrete(range = c(5,20)) +  guides(size=FALSE, colour=FALSE)
# forplotly <- x2
# forplotly <- summarise(group_by(x2, val, com, id), number = n(), y = mean(y))

# ANOVA Test
aovval <- aov(y~SLval4, df)
summary(aovval)
aovcom <- aov(y~SLcom4, df)
summary(aovcom)
lmid <- lm(y~sla_id, df)
summary(lmid)
#Only SLval4 shows significant result
TukeyHSD(aovval)
```
3D plot here:
https://plot.ly/~rikku1983/35/visualization-of-acculturation-and-attitude-for-seeking-professional-counseling/?share_key=0poL7ODE8G2eg9itKxkbs6

## Making data ready for modeling
1. Missing values
For convenience, we just remove all rows with NAs. We end up having a data with 110 observations and 10 variable.

```{r, echo=FALSE, message=FALSE}
## Get rid of unnecessary columns
df2 <- df[,c(26, 1:6, 23,25, 11)]
df4<-df2[complete.cases(df2),]
```

2. Convert all variable type to ones ready for analysis
```{r,echo=FALSE, message=FALSE}
#gender
df4$gender[df4$gender==1] <- "man"
df4$gender[df4$gender==2] <- "woman"
df4$gender <- factor(df4$gender, levels=c("man", "woman"))
#degree
df4$degree[df4$degree == 1] <- "undergraduate"
df4$degree[df4$degree == 2] <- "master"
df4$degree[df4$degree == 3] <- "doctoral"
df4$degree <- factor(df4$degree, levels = c("undergraduate", "master", "doctoral"))
#marital
df4$marital[df4$marital==1] <- "single"
df4$marital[df4$marital==2] <- "married"
df4$marital <- factor(df4$marital, levels=c("single", "married"))
#religion
df4$religion[df4$religion==1] <- "christian"
df4$religion[df4$religion==2] <- "atheist"
df4$religion[df4$religion==3] <- "Buddhist"
df4$religion <- factor(df4$religion, levels=c("atheist", "christian", "Buddhist"))
#SLval4
df4$SLval4 <- factor(df4$SLval4, levels = c("B", "A","N","W"))
#SLcom4
df4$SLcom4 <- factor(df4$SLcom4, levels = c("B", "A","N","W"))

sapply(df4, class)
```

# Analysis of relationship between each variables

## Association between different variables
In this part, we start to look into relationship between different variables in this table by studying there correlations

```{r, echo=FALSE, message=FALSE}
panel.hist <- function(x, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(usr[1:2], 0, 1.5) )
  h <- hist(x, plot = FALSE)
  breaks <- h$breaks; nB <- length(breaks)
  y <- h$counts; y <- y/max(y)
  rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y))
  txt <- format(c(r, 0.123456789), digits = digits)[1]
  txt <- paste0(prefix, txt)
  if(missing(cex.cor)) cex.cor <- 1/strwidth(txt)
  text(0.5, 0.5, txt, cex = cex.cor * r+1)
}
pairs(df4, panel=panel.smooth, diag.panel = panel.hist, lower.panel = panel.cor)
par(mfrow=c(2,2))
hist(df4$age)
hist(df4$stay)
hist(log(df4$age))
hist(df4$stay^(1/3))

df5 <- mutate(df4, stay=stay^(1/3), age=log(age))
pairs(df5, panel=panel.smooth, diag.panel = panel.hist, lower.panel = panel.cor)
```

Compare df4 and df5, the correlation between age and response drop from 0.0075 to 0.0042, and the correlation between stay and response increase from 0.083 to 0.089. Basically, not very significant change were observed. So we will live with non-transformed data.
Among our predictors, we observe highest correlations between age and marital status (0.55) and, age and degree(0.46). 

Due to the correlations showed in this figuer is just pearson correlation which might not be appropriate for categorical data. So we will build the effect size matrix by using more appropriate measure for different type of data.

for numeric vs numeric: Pearson's correlation is used, absolute value of this r is categorized as followed, Effect size  r
Small	      0.10
Medium	    0.30
Large	      0.50[1][2]

for numeric vs categorical: R square from one-way ANOVA is taken and the square root value is used so that we can compare it to other effect size


for categorical vs categorical: Cramer's V
df*  small	medium	large
1	     .10	   .30	  .50
2	     .07	   .21	  .35
3	     .06	   .17	  .29

```{r, echo=FALSE, message=FALSE}
corr<-df4[1:10,];corr[,]<-0
corr <- as.matrix(corr)
diag(corr) <- 1
rownames(corr) <- colnames(corr)
N <- nrow(df4)
for(i in 1:(ncol(df4)-1)){
  for(j in (i+1):ncol(df4)){
  type <- (class(df4[,i])=="numeric") + (class(df4[,j])=="numeric")
  if(type==0){
    corr[i,j] <- cramersV(df4[,i], df4[,j])
  }
  else if(type==1){
    if(class(df4[,i])=="numeric"){
      sumsq <- summary(aov(df4[,i]~df4[,j]))[[1]][,2]
      corr[i,j] <- sqrt(sumsq[1]/(sumsq[1]+sumsq[2]))
    }
    else{
      sumsq <- summary(aov(df4[,j]~df4[,i]))[[1]][,2]
      corr[i,j] <- sqrt(sumsq[1]/(sumsq[1]+sumsq[2]))
    }
  }
  else{
    corr[i,j] <- abs(cor(df4[,i], df4[,j]))
  }
  }
}
```

Visualizing the association

```{r, echo=FALSE, message=FALSE}
corr[lower.tri(corr)] <- NA
kable(corr)
rownames(corr) <- colnames(corr)
corr_palette <- colorRampPalette(c("black", "red"))(n = 1000)
heatmap.2(corr, Rowv=NA, Colv=NA, scale = "none", col=corr_palette, dendrogram="none", trace="none", key=F, margins = c(5, 5))
```

# Fit regression
1. Model without interaction

```{r, echo=FALSE, results='hide', message=FALSE}
fm <- lm(y~., df4)
summary(fm)
noint <- step(fm)
summary(noint)
```

2. Model with interactions

```{r, echo=FALSE, results='hide', message=FALSE}
fmint <- lm(y~.*., df4)
summary(fmint)
allint <- step(fmint)
summary(allint)
```

Model with all possible interactions after backward selection, has much higher R squared but also much more predictors, and the design matrix is not full rank any more. So colinearity and multicolinearity is brought in. 
Let's try less interaction. We will try just one variable interacting with all others to see if there would be any improvement of r squared.

3. more parsimoneous model

```{r, echo=FALSE, message=FALSE}
sl5 <- lm(y~degree + stay + marital + SLval4 + sla_id + SLcom4 + sla_id:age + sla_id:degree + age:degree + stay:SLval4, df4)
summary(sl5)
betint <- step(sl5)
summary(betint)
```

All models we have 
fmstep: full model without interactions
    all following are with interactions
fmintstep: with all possible interaction

## Compare all models

```{r, echo=FALSE, results='hide', message=FALSE}
compare<-rbind(c(summary(noint)$df[1], AIC(noint), BIC(noint), summary(noint)$adj.r.squared),
      c(summary(allint)$df[1], AIC(allint), BIC(allint), summary(allint)$adj.r.squared),
      c(summary(betint)$df[1], AIC(betint), BIC(betint), summary(betint)$adj.r.squared)
      )
colnames(compare) <- c("df", "AIC", "BIC", "Ajusted R2")
rownames(compare) <- c("no interaction", "all interaction", "some interaction")
```

```{r, echo=FALSE, message=FALSE}
kable(compare)
```
# Final model

```{r, echo=FALSE, message=FALSE}
summary(betint)
par(mfrow=c(2,2))
plot(betint)
```

Final formula
y ~ degree + stay + marital + SLval4 + sla_id + sla_id:age + degree:sla_id + degree:age + stay:SLval4

This indicates
1. If a chinese student with age 20, undergraduate degree, just arrive US, not married, got "B" as his value, and got "1" in identification, his altitude for seeking professional counseling is predicted to be 27.2091 + 3.21046 - 0.25015 * 20 = 25.41656

2. Effect of degree
Compare degrees assume all other parameters are the same
  2.1 the difference of y between master degree and undergraduate degree:
    -16.28808 + 2.39256 * sla_id + 0.52561 * age
  2.2 the difference of y between doctor degree and undergraduate degree:
    -12.67931 + 3.98390 * sla_id + 0.34156 * age
Visualize it

```{r echo=FALSE, message=FALSE}
range(df4$age)
# let x is age, set from 18 to 50
x <- 18:50
ym1 <- x * 0.52561 + 2.39256 -16.28808
ym2 <- x * 0.52561 + (2.39256 * 2 )-16.28808
ym3 <- x * 0.52561 + (2.39256 * 3 )-16.28808
ym4 <- x * 0.52561 + (2.39256 * 4 )-16.28808
ym5 <- x * 0.52561 + (2.39256 * 5 )-16.28808
# mas <- cbind(x,ym1,ym2,ym3,ym4,ym5)

yd1 <- x * 0.34156 + 3.98390 -12.67931
yd2 <- x * 0.34156 + (3.98390 * 2 )-12.67931
yd3 <- x * 0.34156 + (3.98390 * 3 )-12.67931
yd4 <- x * 0.34156 + (3.98390 * 4 )-12.67931
yd5 <- x * 0.34156 + (3.98390 * 5 )-12.67931
# doc <- cbind(x,yd1,yd2,yd3,yd4,yd5)
id1 <- cbind(x, ym1, yd1)
id2 <- cbind(x, ym2, yd2)
id3 <- cbind(x, ym3, yd3)
id4 <- cbind(x, ym4, yd4)
id5 <- cbind(x, ym5, yd5)
agedf <- as.data.frame(rbind(id1,id2,id3,id4,id5))
agedf$id <- rep(c("id=1", "id=2", "id=3", "id=4", "id=5"), each=33)
names(agedf) <- c("age", "master", "doctor", "SLA_id")
# ageplot <- as.data.frame(rbind(mas, doc))
# ageplot$dg <- rep(c("master", "doctoral"), each=length(x)) 
# names(ageplot) <- c("age", "id1", "id2", "id3","id4","id5", "degree")
page <- ggplot(data=agedf) + geom_line(aes(x=age, y=master, colour = "master")) + facet_grid(. ~ SLA_id) + geom_line(aes(x=age, y=doctor, colour="doctor")) + labs(y="change in y") + guides(colour=guide_legend(title= NULL))
page
```

2. Effect of stay length(in month) in US
  3.1 For people with Asian Value (got "A" from question 22 and 23): every one more month people has stayed in US will decrease the y value by 0.01368
  3.2 For people with Bicultural value (got "B" from question 22 and 23): every one more month people has stayed in US will increase the y value by 0.03273
  3.3 For people with Western value (got "W" from question 22 and 23): every one more month people has stayed in US will decrease the y value by 0.0539
  3.4 For people with neither value (got "N" from question 22 and 23): every one more month people has stayed in US will decrease the y value by 0.116628



3. married people tend to be less willing for seeking professional counseling, because when all other variable are the same, married people would have 1.56708 less in y value

4. Compare different values
  4.1 the difference of y between W and A:
    3.487880 - 0.040218 * stay
  4.2 the difference of y between B and A:
    -0.685641 + 0.046410 * stay
  4.3 the difference of y between N and A:
    3.832049 - 0.102949 * stay
    
visualize effect of stay and values on changes of y comparing with y given value is "B" and stay=0,  and all other variables are the same

```{r, echo=FALSE, message=FALSE}
x <- 0:300
ya <- (0.03273 - 0.04641) * x + 0.68564
yb <- 0.03273 * x
yn <- (0.03273 - 0.14936) * x + 4.51769
yw <- (0.03273 - 0.08663) * x + 4.17352
staydf <- data.frame(stay = rep(x, 4), deltay <- c(ya, yb, yn, yw), val=rep(c("A", "B", "N", "W"), each=301))
pstay <- ggplot(data=staydf, aes(x=stay, y=deltay, colour=val)) + geom_line() + geom_point(data=df4, aes(x=stay, y=y-mean(y), colour=SLval4))
pstay

coplot(y~stay|SLval4, df4)
```

We notice there is a point of value = "A" outling and might have huge leverage. Lets remove it and refit the model

```{r, echo=FALSE, message=FALSE}
df6 <- df4[!(df4$stay>250),]
sl6 <- lm(y~degree + stay + marital + SLval4 + sla_id + SLcom4 + sla_id:age + sla_id:degree + age:degree + stay:SLval4, df6)
summary(sl6)
betint6 <- step(sl6)
summary(betint6)

#visualize
x <- 0:300
ya <- (0.03283 - 0.04271) * x + 0.59180
yb <- 0.03283 * x
yn <- (0.03283 - 0.14879) * x + 4.49134
yw <- (0.03283 - 0.08677) * x + 4.17165
staydf6 <- data.frame(stay = rep(x, 4), deltay <- c(ya, yb, yn, yw), val=rep(c("A", "B", "N", "W"), each=301))
pstay6 <- ggplot(data=staydf, aes(x=stay, y=deltay, colour=val)) + geom_line() + geom_point(data=df6, aes(x=stay, y=y-mean(y), colour=SLval4))
pstay6
coplot(y~stay|SLval4, df6)
```
We found the point has negligible effects, so we will maintain it.


5. effect of sla_id
  5.1 For undergraduate degree
    3.210456 - 0.250148 * age
  5.1 For master degree
    3.210456 - 0.250148 * age + 2.392557
  5.2 For Doctor degree
    3.210456 - 0.250148 * age + 3.983903 

Lets visulize changes of y due to degree, sla_id and age together with all other variables stay the same
```{r, echo=FALSE, message=FALSE}
# let x is age, set from 18 to 50
x <- 18:50
#for undergraduate
yu1 <- (3.21046 -0.25015 * x) * 1
yu2 <- (3.21046 -0.25015 * x) * 2
yu3 <- (3.21046 -0.25015 * x) * 3
yu4 <- (3.21046 -0.25015 * x) * 4
yu5 <- (3.21046 -0.25015 * x) * 5

#for master
ym1 <- x * 0.52561 + (2.39256 * 1) - 16.28808 + (3.21046 -0.25015 * x) * 1
ym2 <- x * 0.52561 + (2.39256 * 2) - 16.28808 + (3.21046 -0.25015 * x) * 2
ym3 <- x * 0.52561 + (2.39256 * 3) - 16.28808 + (3.21046 -0.25015 * x) * 3
ym4 <- x * 0.52561 + (2.39256 * 4) - 16.28808 + (3.21046 -0.25015 * x) * 4
ym5 <- x * 0.52561 + (2.39256 * 5) - 16.28808 + (3.21046 -0.25015 * x) * 5
# mas <- cbind(x,ym1,ym2,ym3,ym4,ym5)

yd1 <- x * 0.34156 + (3.98390 * 1) -12.67931 + (3.21046 -0.25015 * x) * 1
yd2 <- x * 0.34156 + (3.98390 * 2) -12.67931 + (3.21046 -0.25015 * x) * 2
yd3 <- x * 0.34156 + (3.98390 * 3) -12.67931 + (3.21046 -0.25015 * x) * 3
yd4 <- x * 0.34156 + (3.98390 * 4) -12.67931 + (3.21046 -0.25015 * x) * 4
yd5 <- x * 0.34156 + (3.98390 * 5) -12.67931 + (3.21046 -0.25015 * x) * 5
# doc <- cbind(x,yd1,yd2,yd3,yd4,yd5)
id1 <- cbind(x, yu1, ym1, yd1)
id2 <- cbind(x, yu2, ym2, yd2)
id3 <- cbind(x, yu3, ym3, yd3)
id4 <- cbind(x, yu4, ym4, yd4)
id5 <- cbind(x, yu5, ym5, yd5)
adidf <- as.data.frame(rbind(id1,id2,id3,id4,id5))
adidf$id <- rep(c("id=1", "id=2", "id=3", "id=4", "id=5"), each=33)
names(adidf) <- c("age", "undergraduate", "master", "doctor", "SLA_id")
# ageplot <- as.data.frame(rbind(mas, doc))
# ageplot$dg <- rep(c("master", "doctoral"), each=length(x)) 
# names(ageplot) <- c("age", "id1", "id2", "id3","id4","id5", "degree")
padi <- ggplot(data=adidf) + geom_line(aes(x=age, y=undergraduate, colour = "undergraduate")) + facet_grid(. ~ SLA_id) + geom_line(aes(x=age, y=master, colour="master")) + geom_line(aes(x=age, y=doctor, colour="doctor")) + labs(y="change in y")  + guides(colour=guide_legend(title= NULL))
padi
```

6. effect of age
  6.1 doctor degree
    6.1.1 sla_id = 1: 0.341559-0.250148 = 0.091411 > 0
    6.1.2 sla_id = 2-5: 0.341559 - 0.250148 * sla_id < 0
  6.2 master degree
    6.2.1 sla_id=1-2: 0.525614 - 0.250148 * sla_id  > 0
    6.2.2 sla_id=3-5: 0.525614 - 0.250148 * sla_id  < 0

#Result:
This model explains 31.39% of variation in y. It contains 17 variables (including dummy variables). two main interaction groups are revealed: 1, stay length and values. 2. degree, age and identifications. This model indicating

*Analyzing first interacting group shows

1. Interestingly, stay length has negative impact on y within groups of people with values of "A", "W" and "N". While stay length has positive impact on y within group of people with values of "B". 
2. Western values shows highest positive impact when people stay in US between 5.48653 and 48.12083 months, which constitutes `r sum(df4$stay >5.48653&df4$stay<48.12083)/nrow(df4)` of all our observations. And western value showed more positive impact on our y than asian value when the stay length is less than 81.24943 months, which consititutes `r sum(df4$stay >5.48653&df4$stay<48.12083)/nrow(df4)`
of our all obervations.
This tells us western values has most positive impact, especially more positive than asian values, on our y in most of our samples. 
Try less complex model.

*The second interacing group involves degree, age and identifications, analyzing it shows:

1. in most cases, age is a negative factor on our y, except in groups of people with master degree and identification of 1 and 2 and group of people with doctoral degree with identification of 1. Which means if you are more asian identified and with advanced degree, the older you are, the more likely you are seeking for professional counseling. 
2. More significantly, the more western you identify yourself, the age tend to have more negative impact on y. The higher degree you have, the more likely you are seeking for professional counseling. And interetingly, advanced degree tend to lower the rate of decressing of y due to age increasing. 
3. Moreover, within group of people with undergraduate degree and at the same age, the more western they identified themself, the smaller y we get. And this difference increases along the age. in advanced degree, this trend changed. For example, in group of people with doctoral degree, during young age, younger than 30, the more western they identify themselves, the higher y they get. However, when age is bigger, they got less y instead. 

*Also we observe married people has less y.
  
```{r, echo=FALSE}
# lower <- lm(y~., df4)
# lower2 <- lm(y~SLval4 + degree + stay, df4)
# upper <- lm(y~.+.:., df4)
# test <- step(lower2, scope=y~.*., direction = "forward", steps = 8)
# teststep <- step(test)
# summary(test)
# BIC(test)
# 
# sl6 <- lm(y~degree + stay + marital + SLval4 + sla_id + SLcom4 + sla_id:degree + stay:SLval4, df4)
# summary(sl6)
# betint2 <- step(sl6)
# summary(betint2)
# BIC(betint2)
```


Reference
1. Jacob Cohen (1988). Statistical Power Analysis for the Behavioral Sciences (second ed.). Lawrence Erlbaum Associates.
2. Cohen, J (1992). "A power primer". Psychological Bulletin 112 (1): 155-159. doi:10.1037/0033-2909.112.1.155. PMID 19565683.